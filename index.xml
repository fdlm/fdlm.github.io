<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fdlm.github.io</title>
    <link>https://fdlm.github.io/</link>
    <description>Recent content on fdlm.github.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 22 Dec 2017 10:37:55 +0100</lastBuildDate>
    
	<atom:link href="https://fdlm.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Experiments with AMSGrad</title>
      <link>https://fdlm.github.io/post/amsgrad/</link>
      <pubDate>Fri, 22 Dec 2017 10:37:55 +0100</pubDate>
      
      <guid>https://fdlm.github.io/post/amsgrad/</guid>
      <description>For ICLR 2018, two papers targeting problems with the ADAM update rule were submitted: On the Convergence of Adam and Beyond, and Fixing Weight Decay Regularization in Adam. The former points to a flaw in ADAM&amp;rsquo;s proof of convergence, and provides a simple solution. The resulting algorithm is called AMSGrad. The paper shows the advantages of AMSGrad on a synthetic task and a small number of experiments. However, it only uses small networks (1-layer MLP on MNIST, and a small ConvNet for CIFAR-10), and does not show test accuracy, the metric we ultimately care about more than cross-entropy loss.</description>
    </item>
    
    <item>
      <title>A Fully Convolutional Deep Auditory Model for Musical Chord Recognition</title>
      <link>https://fdlm.github.io/post/auditorymodel/</link>
      <pubDate>Sun, 24 Jul 2016 08:38:14 +0200</pubDate>
      
      <guid>https://fdlm.github.io/post/auditorymodel/</guid>
      <description>This site contains information on reproducing the experiments in the paper
A Fully Convolutional Deep Auditory Model for Musical Chord Recognition
Korzeniowski, F. and Widmer, G.
In Proceedings of the IEEE International Workshop on Machine Learning for Signal Processing (MLSP), Salerno, Italy, 2016.
Software The pre-trained chord recognition model is available as part of the madmom audio processing framework. It differs only slightly from the model presented in the paper: instead of padding the input in the first few convolutional layers, we use a larger context window in the input layer, such that the feature map size after the first pooling layer is retained.</description>
    </item>
    
    <item>
      <title>The Deep Chroma Extractor</title>
      <link>https://fdlm.github.io/post/deepchroma/</link>
      <pubDate>Mon, 23 May 2016 09:22:08 +0200</pubDate>
      
      <guid>https://fdlm.github.io/post/deepchroma/</guid>
      <description>This page contains additional information and data necessary to reproduce the results of the following paper:
F. Korzeniowski and G. Widmer. &amp;ldquo;Feature Learning for Chord Recognition: The Deep Chroma Extractor&amp;rdquo;. In Proceedings of the 17th International Society for Music Information Retrieval Conference (ISMIR 2016), New York, USA.
Software The pre-trained feature extractor is available as part of the madmom audio processing framework as the DeepChromaProcessor class. Note that the model bundled with madmom differs from the one we used in the paper: it uses less units in the hidden layers of the neural network and operates on a narrower frequency band.</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>https://fdlm.github.io/projects/</link>
      <pubDate>Wed, 27 Jan 2016 11:51:04 +0100</pubDate>
      
      <guid>https://fdlm.github.io/projects/</guid>
      <description>This page gives a short description of the projects I developed or am involved in on GitHub.
rtHMM rtHMM is a C++ library implementing the major inference algorithms for Hidden Markov Models. I designed it with a focus on real-time data processing. It thus efficiently handles large state spaces, especially if they are sparse. I developed it at the beginning of my PhD studies for a HMM-based score following system.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://fdlm.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fdlm.github.io/about/</guid>
      <description>I am a PhD researcher at the Department of Computational Perception of the Johannes Kepler University in Linz, where I work on probabilistic models and deep neural networks for audio/music processing. Currently I am interested in extracting musical artifacts such as (down-)beats and chords/harmonies from audio recordings to faciliate a richer computational understanding of music.
 Find me on&amp;hellip;
GitHub + Soup + Twitter</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>https://fdlm.github.io/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fdlm.github.io/publications/</guid>
      <description>2018 Improved Chord Recognition by Combining Duration and Harmonic Language Models
Korzeniowski, F. and Widmer, G.
In Proceedings of the 19th International Society for Music Information Retrieval Conference (ISMIR), Paris, France, 2018.
Genre-Agnostic Key Classification With Convolutional Neural Networks
Korzeniowski, F. and Widmer, G.
In Proceedings of the 19th International Society for Music Information Retrieval Conference (ISMIR), Paris, France, 2018.
Automatic Chord Recognition with Higher-Order Harmonic Language Modelling
Korzeniowski, F.</description>
    </item>
    
  </channel>
</rss>